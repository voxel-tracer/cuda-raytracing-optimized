---------------------------------------------------------------------------------------------------------
FEATURES
---------------------------------------------------------------------------------------------------------

 LOW POLYGON RENDERER (PHASE I)
 --------------------------
- one line summary
  apply all the optimization techniques I learned so far to produce high quality renders really quickly
  (this is the same work I've been doing for the past year but with great looking renders)
- required features
 . support low poly models that can fit in constant memory. I may simplify models to reduce their poly count
 . support a few interesting materials that produce great renders
   (tinted glass, subsurface scattering, coat)
 . basic lighting and background setup that produces great renders
 . apply all the optimizations I learned so far along with any other optimization that may improve the
   performance of the renderer (SAH BVH building, russian roulette, ...)
   UPDATE: rather than spending time on optimizations that will probably get obsolete once we move to phase 2
   focus more on the renderer features regardless of its performance (russian roulette, subsurface scattering, hard coded material kernel code, ...)

- optional features
 . transparent bg with invisible plane that allows you to change to color of the whole background while keeping
   the shadows and reflections on the floor

 HIGH QUALITY POLYGON RENDERER (PHASE II)
 ----------------------------------------
- one line summary
  enhance phase 1 renderer to support high quality models (sculptures) and optimize BVH construction/traversal
  to render the models as quickly as possible (ideally in real-time)
- required features
 . port my spheres BVH and wavefront renderer to support triangle meshes
 . explore advanced optimization techniques
 
 PBR MATERIAL EDITOR (PHASE III)
 ------------------------------
- one line summary
  allow user to configure PBR materials and replace existing sculpture materials with those
  producing incredible renders (think CGTrader Marvel/DC Comics renders) really fast
- may make sense to support Nvidia MDL at some point
 . start by implementing MDL's basic components on my own to understand the theory behind them
 . then integrate MDL with my renderer as it supports generating CUDA code directly

 OTHER DELIVERABLES IN NO PARTICULAR ORDER
 -----------------------------------------
- raylib mesh viewer that supports rendering directly to the viewport
 . we can start with render goes straight to disk
 . this will be useful when building my own rendering/material tool
- integrate with Lighthouse 2
 . we get a model loader/viewer for free
 . we get PBRT scenes loading for free
 . we get a lots of physically-based materials for free
 . we can compare performance of my renderer vs others
 . this is useful when I just want to focus on the render core and optimize it
- advanced materials: implement Disney BRDF and add UI to configure materials
  MDL seem to be a better alternative
- allow setting different material per original model color
- integrate with Optix denoiser to greatly improve the render quality of my preview renderer

 IMPROVEMENTS IN NO PARTICULAR ORDER
 -----------------------------------
- DONE use MeshLab to simplify complex models so they can fit in constant memory
- DONE when importing a model, define its orientation (up vector) and make sure its loading
  in the correct orientation. Makes it easier to use a standard camera position and orient
  the environment map
- camera distance is computed automatically such that the whole model is visible in the viewport
- transparent background (useful to create interesting renders in Gimp)
 . note that ideally we want to capture the full RGB of the background/floor as an ALPHA channel but no image format
   supports this
 . alternative is to treat background/floor differently when hit by primary ray
  . use a different color defined by the user that doesn't affect the scene
- resume rendering from saved file (useful when we want to add more samples to an already expensive render)
- can we preprocess the triangles to identify the ones that don't face any other triangle from the model ?
 . we could use this to quickly identify no_hits for secondary rays
- NOPE Gimp "White Balance" improves the quality of the final renderer
 . can I implement the same strategy in my renderer ?
- all rendering params are configurables from a simple test file. Create a separate file per test scene
- once I implement wavefront renderer, use CUDA graphs to optimize lunching the kernels
- Improve wavefront termination condition as follows (for offline mode):
 . track number samples completed for each pixel
 . once num samples for pixel p reach ns, increment global numDonePixels counter
 . host checks if numDonePixels == (nx * ny) every few iterations to stop the renderer
 . keep sampling pixels that completed all their samples but we don't need to account their color in the framebuffer
   if it helps keeping the logic simpler
- explore using Aila's ray-triangle intersection logic that precomputes a transformation matrix at startup
  this may reduce register usage and improve rendering performance

---------------------------------------------------------------------------------------------------------
PHASE I.1: POLYGON RENDERER
---------------------------------------------------------------------------------------------------------
 REQUIREMENTS
 ------------
- support triangle mesh .obj models that fit in constant memory
- support a few interesting materials that produce great renderers
 . DONE tinted glass with Beer-lambert model
 . DONE existing plastic/coat (diffuse + glass)
- DONE basic lighting and background setup that produces great renderers

 DELIVERABLES
 ------------
- great looking renders that may be too slow to renderer

 TASKS
 -----
- DONE render obj model
- DONE floor
- DONE light and next event estimation
- DONE Lambert-Beer absorption

 PERF
 ----
- tinted-glass on coat 1200x800x4096 in 1045s (17m45s)
----------------------------------------------------------------------------------------------------------
PHASE I.2 BASIC OPTIMIZATIONS (got 3.5x speedup)
----------------------------------------------------------------------------------------------------------
- use the ray stats I collected and identify strategies to reduce total number of traced rays
- apply optimization strategies from my previous work without introducing a full BVH
- target 20x speedup => tinted on coat w 4096spp should render in < 1mn (vs +20mn now)
- do not worry about good design as we are mostly interested by the performance of the renderer
 
 DELIVERABLES
 ------------
- Fast renderer that can be extended with more expensive materials (in phase 1.3)  and larger models (in phase 2)
  Render tinted-glass on coat w 4096spp < 1mn
  UPDATE current performance is good enough (<7mn) for now as I will most likely move to my wavefront/BVH renderer soon

 PROGRESS
 --------
 1045s (17m45s) > 757s (12m37s) > 531s (8m51s) > 395s (6m35s) > 350s (5m50s) > 290s (4m50s) > 278s (4m38s)

 TASKS
 -----
- DONE handle floor as proper infinite plane in kernel
- DONE compute bounding box for the mesh and use it to quickly discard rays
  PERF: 1045s (17m45s) > 757s (12m37s) = 25% speedup
- DONE measue how many secondary rays are from the mesh
- DONE measure how many secondary rays are nohit
- DONE if N samples of same pixel didn't hit the model then remaining samples should just intersect the floor
  in total we pruned 2.7B rays but 2.2B of those rays were bb nohit anyway so not much performance gain
- DONE build a simplified grid acceleration structure
  for N^3 grid rays will at most traverse 3N => 
  N=2 => 4x, N=4 => 5x, N=8 => 20x
  PERF 757s > 531s (8m51s) = 30% speedup
- DONE investigate perf bottlenecks of grid (suspect its too much memory access)
 . increased register count => less occupancy
 . reduced warp efficiency
 . increase memory reads
- DONE copy grid to constant memory
  PERF 531s > 395s (6m35s)
- DONE analyse perf bottlenecks
 . increased register count => less occupancy
 . reduced warp efficiency
 . lots of execution dependency related to loading triangles from constant memory
- NOPE split kernels to reduce register usage
  do not use advanced optimizations (persistent threads, ...)
 . DONE create path struct and use it in kernel code
 . DONE introduced path.specular and fixed caustics
 UPDATE: too much complexity added too soon and register count didn't get that low (still +70 registers for the traversal logic)

- DONE interpolate vertice normals
	ptxas info    : Used 86 registers, 576 bytes cmem[0], 244 bytes cmem[2]
 . DONE rewrite intersection logic to delay computing most intersection details after we find closest hit
    ptxas info    : Used 82 registers, 576 bytes cmem[0], 264 bytes cmem[2]
 . DONE expose hit uv coordinates from hitMesh() + more replace hit_record with tri_hit
    ptxas info    : Used 78 registers, 576 bytes cmem[0], 264 bytes cmem[2]
 . DONE found small optimization with shadow rays (we don't need to intersect them with plane and we don't need to compute intersection details for them)
	PERF 395s (6m35s) > 350s (5m50s)
 . DONE copy mesh normals to global memory and expose pointer to RenderContext
 . DONE color() computes interpolated normal when hitIdx == MESH_HIT
    ptxas info    : Used 84 registers, 584 bytes cmem[0], 264 bytes cmem[2]
	PERF is worse 401s even when disabling interpolated normals
 . DONE copy normals to constant memory
	didn't improve performance

- NOPE adaptive sampling to skip pixels that don't have any specular light hit nor mix of shadow/no shadow hits
 . skip pixels that don't hit anything after X spp (X=32)
 . skip pixels that don't hit mesh in any bounce and in their primary shadow)
   PERF is actually worse, most likely because those skipped pixels weren't expensive to compute in the first place and the added
    complexity and register usage affects all pixels

- DONE russian roulette
	PERF 350s > 290s (4m50s)
 . using stats register usage goes down from 84 -> 79 !
 . perf is worse without stats!!!

- DONE investigate stat diff after material refactoring
  one issue was caused by epsilon too small causing self intersections
  some faces have a wrong orientation causing the renderer to interpret their intersection as exiting from model
 . refactor logic to always reorient normal and use other ways to identify entry/exit from model
 . fixing this issue reduced register usage to 79 and 
	PERF 290s > 278s (4m38s)
- store triangle normal in constant memory

----------------------------------------------------------------------------------------------------------
PHASE I.3 SUBSURFACE SCATTERING
----------------------------------------------------------------------------------------------------------

- DONE implement subsurface scattering
 . takes time to get used how to properly configure
 . has a lot of variation even with 16K samples
  . makes sense to implement some variation reducing techniques like splitting (less rays per pixel and more scattered rays)
  . better phase functions should improve convergence

 NOTES
 -----
- Disney BRDF initially didn't contain subsurface scattering, so we may get a lot of interesting renders without sss
- after this phase is done it makes sense to cleanup the rendering code and simplify it to fit in a single cuda file
  then write a quick tutorial explaining all the optimizations that got it to run that fast
  . similar to https://fabiensanglard.net/revisiting_the_businesscard_raytracer/card_cudc.html

----------------------------------------------------------------------------------------------------------
PHASE II SUPPORT LARGE TRIANGLE MESH MODELS
----------------------------------------------------------------------------------------------------------
 NOTES
 -----
- DONE we should start with spheres project and update it to support triangle meshes
- NOPE update bvh-renderer to be at par with grid-renderer:
 . colored background
 . support for multiple materials
 . floor/box with dedicated material
- DONE start by making minimum changes to support triangle meshes, we don't want to refactor the code as its a big
  mess and eventually we want to move away from that project
- current spheres project no longer uses constant or texture memory
 . not sure why but I guess that's good as it will be less distraction when analysing its perf

----------------------------------------------------------------------------------------------------------
PHASE II.1 UPDATES SPHERES TO SUPPORT TRIANGLE MESHES
----------------------------------------------------------------------------------------------------------
 TASKS
 -----
- DONE start by removing colors and updating code accordingly to only use modelColor
 . bModelColor always set to true	
- DONE update loadScene() to load triangle meshes using tinyobj
 . DONE introduce tri struct only needed during loading/bvh building
	. has a center field
 . DONE update scene to use tri* instead of sphere*
 . DONE update build_bvh() to accept tri* instead of sphere*
  . it's mostly the same, we just need to update minof() and maxof() to handle tri instead of sphere
  . we also need to update box_x/y/z_compare, if we use the tri centroids we can actually compute those centrois 
    when loading the model as tri.center that way we don't need to change box_x/y/z_compare
 . change loadFromPLY() to loadFromOBJ() and use tinyobj
- DONE after scene is loaded convert tri* to vec3* and pass them to renderContext
 . RenderContext stores tri* and numTris instead of sphere*, it also no longer contains colors
- DONE change trace_scattered() and trace_shadows() to use hit_triangle() instead of hit_point()
- DONE change update() to just use modelColor (already exists) instead of colors

- DONE found issue with teapot and bunny models: they both have holes in them
  that's why subsurface scattering looks wrong
- DONE fix loading dragon model
 . using uint16_t doesn't work for large models
- DONE make it easy to set UP vector for the camera (and floor ?)

- DONE looks like bvh traversal has a bug in it, as it tries to read non existing triangles
 . shadow rays were generated with a NaN direction

- DONE get a sense of how fast bvh renderer compared to the grid renderer
 . easiest is to change the grid renderer so that it matches the render settings of the bvh renderer
  . DONE only compare models that are yUp: teapot, bunny, dragon, catfolkrogue
	teapot scale = 100, camera.dist = 120
	bunny scale = 50, camera.dist = 120
	dragon scale = 100, camera.dist = 200
	
  . DONE camera looks at scene.bounds.max.y/2
  . DONE center model on top of floor
  . DONE camera.fov = 20
  . DONE no floor
  . DONE constant sky color
  . DONE show sky color
  . DONE same model color
  . DONE same light settings
  . DONE max bounces = 10
  . DONE disable russian roulette
  . sqrt color before converting to linear sRGB
 . some performance numbers for 512x512 1024spp
	teapot	 39s vs  120s (x3)
	bunny	131s vs  937s (x7)
	dragon  294s vs 1793s (x12)	(1024spp crashed the laptop for the grid renderer, this number is for 512spp)
- DONE fixed NaN issue in generateShadowRays() and somehow register usage went down 64 > 56 !!!

- DONE implement basic bvh building and traversal in mega-kernel renderer (previously grid renderer)
  don't worry about SAH for now
  don't worry about splitting the kernels for now
  . register count 62
	512x512 1024(settings similar to spheres) // 63 registers
	scene			uber-kernel		wavefront	speedup		speedup vs no accel
	-----			-----------		---------	-------		-------------------
	panter			4s				7s			1.75x		
	teapot			22.5s			39s			1.73x		5.3x
	bunny			15s				130s		8.66x		62.4x
	dragon			25s				294s		11.75x		71.2x
  . uber kernel is much faster than wavefront renderer !!!

- DONE there is slight difference in the rendering between spheres and cuda-raytracing
 . cuda-raytracing is consistent before/after bvh so its not related to BVH
- DONE collect perf numbers for various materials on mega-kernel 600x400 1024spp
	materials	registers	no-accel	bvh		speedup
	coat/coat	58/67		47s			15s		x3
	diff/diff				44s			14s		x3
	glass/check	72/71		59s			17s		x3.5
	sss/diff				915s		301s	x3
 
- NOPE collect various stats for cuda-raytracing with/without BVH
 . add easy way to disable BVH traversal
 . explore various materials
 . identify useful stats and hints about when BVH is less performant

 NOTES
 -----
- with BVH, subsurface scattering is faster but still shows lots of variations because its not easy
  to sample the light from inside the model (because of the refraction at the surface)
 . there are ways to improve the sampling (e.g. by using cache points at the surface of the model) and this
   is an interesting problem to solve as it produce really good looking renders
 . splitting can help as well by dedicating more samples to the scattered rays rather than anything else
- find papers around how frozen 2 renders snow statues
	https://blog.yiningkarlli.com/2017/07/spectral-and-decomposition-tracking.html
- took me time to track the memory access issue. What I learned from it:
 . I should have a DBG mode that checks each array idx before we access and print enough hints to point to it
   when we see issues, we can enable DBG mode
 . in DBG mode track NaN in various places of the code and print a warning
- the way I convert colors in grid renderer to sRGB may be wrong
  I should probably not sqrt() the color channel before conversion

 OPTIONAL (don't do these now, leave them until we are ready to refactor the code into a new clean project)
 -------- 
- add option to show floor with a configurable size.
 . I could make it a box so it's prettier
- add versions to .bin files
- for large models, preview window lags too much
 . uncouple rendering of the window from rendering of the model
 . add "preview" mode that renders a coarse version of the model (maybe stop at some level of bvh)
- DONE add scene struct to grid-based renderer
- NOPE material that draws the borders of triangles on top of the material

----------------------------------------------------------------------------------------------------------
PHASE II.2 LOAD AND RENDER STAIRCASE .OBJ SCENE
----------------------------------------------------------------------------------------------------------
 GOAL
 ----
- load complex .obj scene with textured materials
- focus on one specific scene: staircase
- use KnightCrawler's PathTracer as a reference to load and render the scene
	https://github.com/knightcrawler25/GLSL-PathTracer
 . for now only use its camera/light config
- add minimum set of features needed to render the scene
- hard code scene in code (no need to implement .scene loading)
- this provides a concrete goal to target and great looking scenes to render
- once I'm able to render the scene as is I can move to the next phase (optimization)

 TASKS
 -----
- DONE go through the scene description and identify all missing features
 . maxDepth configurable (maxBounce)
 . diffuse albedo texture
 . replace quad light with sphere light
 . load multiple meshes, each with a dedicated material
- DONE make maxDepth configurable

- DONE move BVH building logic to current project as a sub-project
 . create new bvh-builder project
 . copy all bvh building logic in main.cpp
 . outputs .bvh
 . generates header with magic word and version
- DONE build BVH from multiple meshes
 . DONE each triangle has an associated meshID (unsigned char)
 . DONE simplest solution is to open all meshes and collect their stats
   create appropriate arrays
   then open the meshes again and read the data
 . DONE test it by combining two objs together
 . DONE color() uses meshID to use the appropriate material (move logic to scatter())
 . DONE load staircase scene and render it using different colors for each mesh
 . DONE set the correct color for all materials that don't require an albedoTexture
- DONE bug in BVH
- DONE display number of traversed nodes per sample as a heat color
 . DONE for each sample compute number of traversed nodes
 . DONE find max for all samples and use it as a basis for interpolation		1560
 . convert number of traversed nodes per sample to color (0, 0, 1) -> (0, 1, 0) -> (1, 0, 0)
- DONE properly handle texture coordinates
 . load texture coordinates and store them with triangles in BVH
   when texCoords not available just put (0, 0)
 . hitMesh() interpolates proper texCoords (tu, tv) using triangle barycentric coordinates
 . add texture-dbg material that blends 4 colors according to (tu, tv)
 . load casual-effects textured cube and confirm it looks as expected
- DONE add support for albedo textures
 . DONE struct Texture { 
	int width, int height; 
	float *data;
   }
 . DONE initKernel() accepts a Texture[]
   if non empty, create corresponding device textures and stores Texture[] in RenderContext
 . cubeMaterial() uses its default.png texture as albedo texture
 . add proper materials for the staircase scene (hardcode them)
 . see if we need bilinear filtering for the textures and interpolated normals 

 NOTES
 -----
- for now we store with each triangle all its associated infos: meshID, texCoords, ...
  we may want to move those outside BVH later on
- existing models
 . bunny: has texture coords, vertex normals
 . dragon: has vertex normals
 . cube: has texture coords, vertex normals, and a default texture
 . staircase: has texture coords, vertex normals
- we may want to store textures as uint32 colors to save space
- we should use CUDA texture to benefit from faster memory access and bilinear filtering if needed
- support interpolated normals using vertex normals loaded from .obj (when available)
- CUDA texture access works best when all lanes in a warp access the same texture object
----------------------------------------------------------------------------------------------------------
PHASE II.3 OPTIMIZE BVH MEGA KERNEL FOR STAIRCASE SCENE
----------------------------------------------------------------------------------------------------------
 GOAL
 ----
- investigate what are the performance bottlenecks
- optimize the code as much as possible while keeping the mega-kernel model
- 3938s (1h5m38s)

 TASKS
 -----
- DONE measue rendering time for 640x800x1024spp and 64 max depth with russian roulette
- DONE measue rendering time after disabling various features:
 . shadow rays
 . textures
 . ...
- DONE go through my optimization notes and identify what kind of stats I should track to
  identify what to optimize next
- DONE we have different types of rays: primary, secondary-bounceX, shadows
  measure the cost of each type. This will help us identify specific areas to optimize
- Prepare performance profiling
 . DONE print kernel code and identify min info we need to save for each path so we can run next bounce separately
  . origin
  . rayDir
  . specular // flag
  . bounce // same for all rays of the same batch
  . rng
  . inside // flag
  . done // flag
 . write special kernels (create separate project for this):
  . DONE primary kernel: generates primary rays, handles them and save next bounce to memory
   . DONE allocate save_paths[nx*ny*ns]
   . DONE change render() logic to process all ns for the same pixel one after another (to simulate how real renderer works)
   . DONE only generate paths for now
   . DONE saves each path in its correct position according to (x, y, s)
  . DONE refactor scene initialization so we can reuse it
  . DONE color kernel: 
   . loads rays from memory and handles hit() and color() logic for a single bounce
   . handles DONE rays by skipping them (dead lane) and marks done rays accordingly
   . saves color to memory buffer that gets saved to disk so we can visually confirm it works
   . enable shadow and textures and make sure they work as well
  . DONE save rays for each bounce on disk so we can run each bounce separately
  . DONE primary_color kernel:
   . combines primary() and color() kernels to simulate how 1st bounce works in my renderer
  . DONE run bounces and check if we are getting similar performance and stats to the numbers we collected before
		bounce 0 took 4.991 seconds.
		bounce 1 took 11.217 seconds.
		bounce 2 took 12.183 seconds.
		bounce 3 took 12.063 seconds.
		bounce 4 took 11.849 seconds.
		bounce 5 took 11.677 seconds.
		bounce 6 took 11.524 seconds.
		bounce 7 took 11.377 seconds.
		bounce 8 took 11.279 seconds.
	this is actually similar to the times I collected for my original kernel even though memory I/O is higher now
	  because of all the loading/saving of paths
  . DONE add ray stats and make sure they match my original kernel
  . DONE save paths to disk so we can run bounces independently of each other
   . handle primary rays in a special way as we have 2 ways to run them
    . just generate rays
	. generate and handle 1st bounce
- DONE compare primary vs secondary bounces
 . DONE collect nvprof divergence metrics
 . DONE compare runs in visual profiler for bounce 0 and 1
  . 160x200x4spp
- DONE confirm that hitBVH() is the main source of divergence
 . DONE hack the code to force all rays of the same warp to be exactly the same
 . DONE collect efficiency metrics for the perfect case
- DONE understand why warp_execution_efficiency is so low even for primary rays
- DONE collect other metrics
 . collect my own divergence metric
  . print code and identify potential divergence points
- DONE change primaryBounce() to have each warp handle the same pixel
  this should increase traversal coherency and improve both active and leaf metrics
- DONE print active metric per bvh level
  see if higher level have better convergence than lower levels
- DONE Read ray sorting papers and identify strategies worth exploring in my kernel
 . for each strategy, first implement adhoc and test its effect by running a single bounce
   if its effective enough, think about how to implement it in the original kernel
- DONE initial implementation Aila ray sorting using Morton codes
  results are bad, but implmentation is actually wrong as bounce() kernel assumes specific ordering of the paths
- DONE rewrite bounce to handle each sample separately and not using a loop
 . save colors one per sample as we did for primary1
- DONE need to rewrite bounce to handle paths in the order they come in
  perf is still not great (320x400 64spp bounce 1):
			before	sorted
  active	22%		24%
  leaf		5.6%	6.5%
  . not sure if there is a bug in the sorting logic or if the sorting key is just bad
- DONE introduce coherence metric that exposes how much potential coherence can be exploited by
  sorting the rays
  . for N paths, the metric value will range between:
	N = best case, all paths traverse the same nodes
	1 = worst case, each path traverses a unique set of nodes
  . measure the coherence metric for primary and secondary rays at multiple resolution
    we should see it improve when we increase the resolution
	(no shadows)
				resolution		coherence	numpaths	active	leaf	numpaths/coherence(sigma)	(total/unique)
	primary0 	1280x1600x32	  878,459	65,536,000	72%		44%		74					
	primary0 	640x800x64		  442,202	32,768,000	63%		33%		74					
	primary0 	640x800x32		  222,441	16,384,000	63%		33%		74					
	primary0 	320x400x64		  112,346	 8,192,000	53%		24%		73							3,077,943,166 / 27,397
	primary0 	320x400x32		   56,946	 4,096,000	53%		24%		72					
	bounce 1	320x400x64		   57,529	 8,192,000	23%		 6%		141							2,781,000,550 / 48,341
	bounce 2	320x400x64		   47,929	 8,075,841	19%		 5%		168							2,362,004,317 / 49,281
	bounce 3	320x400x64		   46,656	 7,982,478	18%		 5%		170							2,305,323,220 / 49,411
  . coherence = total traversed nodes / unique traversed nodes
	total traversed nodes = num paths x average nodes per path
	sigma = num paths / coherence = unique traversed nodes  average nodes per path
  . I still don't know what sigma means but it normalizes the coherence regardless of nx.ny.ns
    smaller sigma values are better
  . according to the metrics collected, average nodes per path ~375 which too high for a 17 level BVH
  . possible explanation: there is an issue with the traversal algorithm, and/or the BVH quality is too low and there
    is too much overlap between sibling nodes
- DONE investigate why average nodes per path is high
 . I printed the traversal of one random sample through the BVH
 . I found out that loading one child at a time can be really expensive and in many cases only one child is hit yet we
   still back track and try the 2nd child (including a memory load)
 . by loading both siblings at once we can quickly identify if we need to traverse both of them and push the 2nd child to
   the stack
 . additionally we can use the bitstack to do a single back track to the next node that needs to be visited instead of multiple
   consecutive back tracks
 . for 320x400x64 render time went down from 65s to 32s YAY!
- DONE measure how many times both children need to be traversed vs a single one vs none
	both nodes hit      : 2,170,563,557
	single node hit     : 9,214,922,831
 . a smaller proportion of nodes has both children hit the ray, this may suggest a "good" BVH
   can probably be improved with a proper SAH build
- DONE measure coherence, active, and leaf metrics
	(no shadows)
				resolution		coherence	numpaths	active	leaf	numpaths/coherence(sigma)	(total/unique)				avg nodes per path
	primary0 	320x400x64		  110,012	 8,192,000	93%		28%		75							3,185,094,968 / 28,952		388

	bounce 1	320x400x64		   33,952	 8,192,000	55%		10%		241							1,628,687,774 / 47,970
	bounce 2	320x400x64		   48,627	 8,075,841	44%		 8%		166							2,355,322,304 / 49,966
	bounce 3	320x400x64		   47,138	 7,982,478	43%		 8%		169							2,355,322,304 / 49,966
	primary0 	640x800x64		  434,010	32,768,000	95%		35%		75							
	primary0 	640x800x32		  217,968	16,384,000	95%		35%		75					
- DONE nvprof metrics
	primary0
          1                 warp_execution_efficiency                  Warp Execution Efficiency      47.73%      47.73%      47.73%
          1         warp_nonpred_execution_efficiency   Warp Non-Predicated Execution Efficiency      45.26%      45.26%      45.26%
	bounce 1
          1                 warp_execution_efficiency                  Warp Execution Efficiency      20.67%      20.67%      20.67%
          1         warp_nonpred_execution_efficiency   Warp Non-Predicated Execution Efficiency      19.64%      19.64%      19.64%
- DONE primary 1
	active metric       : 97.669705
	leaf metric         : 51.267700
          1                 warp_execution_efficiency                  Warp Execution Efficiency      68.43%      68.43%      68.43%
          1         warp_nonpred_execution_efficiency   Warp Non-Predicated Execution Efficiency      65.02%      65.02%      65.02%
- DONE redo my performance number collection for first 8 bounces (spreadsheet)
 . traversal now accounts for +99%
 . texture handling time is negligeable
 . shadow rays traversal accounts for half rendering time
- DONE collect active/leaf metrics for bounce 0/1
								active	leaf
	original (after dual fix)	
		bounce 0				93%		28%
		bounce 1				55%		10%
	random sorting
		bounce 0				93%		28%
		bounce 1				47%		 8%
	bitstack sorting
		bounce 0				93%		28%
		bounce 1				60%		10%
	Morton code sorting
		bounce 0				93%		28%
		bounce 1				56%		10%
		
- SAH building should improve BVH quality and hopefully improve coherence as well
- given that shadow rays are expensive it makes sense to use splitting to reduce ns overall but increase
  number of shadow rays per intersection.
 . this should improve shadow rays traversal coherence

- go through all the notes in this document and identify optimizations that apply to the mega-kernel
 . truncate low throughput paths (also rename path.attenuation to .throughput)
   generally not that useful except with subsurface scattering, especially if russian roulette is used
- [optional] the way I handle shadow rays is wrong, I should only consider hits that are closer than
  the light itself

 NOTES
 -----
- looking at my older notes, it looks like secondary rays divergence is one of the main bottlenecks and
  even if we fix the idle threads (reuse threads that are done) it won't improve the main problem and may
  make things worse as it will reduce the coherence of primary rays
- list of optimizations
 . store upper BVH levels in constant memory
 . load 2 BVH nodes at a time
 . store lower BVH levels in texture memory
 . store triangles in texture memory
 . use woopified triangle representation
 .implement SAH BVH building algo
- there may be a bug in how we account for light contribution when a ray hits the light directly
 . or maybe we just need a smaller light
- potential optimizations 
 . for primary rays it may make sense to handle all samples of same pixel in consecutive threads rather
   than by the same thread
  . 2 layouts possible:
   . DONE all samples for same pixel in consecutive order starting from (y*nx + x)*ns + s
   . one sample per pixel at (nx*ny)*s + y*nx + x
- primary() + bounce() is different from primaryBounce() kernel because of the way we save rng for each path
----------------------------------------------------------------------------------------------------------
GENERAL NOTES
----------------------------------------------------------------------------------------------------------
- useful nvprof metrics
 . achieved_occupancy
 . branch_efficiency
 . flop_count_dp: number of double precision operations (useful to confirm we aren't using any)
 . warp_execution_efficiency: lower values indicate a large number of idle threads (warps with threads that are done processing their path)
 . warp_nonpred_execution_efficiency: lower values indicate a large number of active threads with divergent execution

----------------------------------------------------------------------------------------------------------
POTENTIAL TARGET GOALS
----------------------------------------------------------------------------------------------------------
- simple OpenGL model viewer
 . easily set camera position
 . easily rotate/translate the model
 . easily orient light
 . easily configure render settings: materials, light, ...
 . ideally starts CUDA renderer and displays progressive rendering
- use MDL as a guide to write my own easy to combine material blocks
  e.g. coat, dielectric and tinted glass share the same fresnel reflection/refraction logic
   find ways to make it easy to combine blocks of code to build those materials
 . instead of writing generic material scattering logic, write custom code that handles the specific
  materials I want to render
 . eventually I can move to a code generation/templating so I can generate kernel code on demand
- move rendering logic to the cloud and build a web editor to interact with the renderer using PixiJS
