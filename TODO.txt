---------------------------------------------------------------------------------------------------------
FEATURES
---------------------------------------------------------------------------------------------------------

 LOW POLYGON RENDERER (PHASE I)
 --------------------------
- one line summary
  apply all the optimization techniques I learned so far to produce high quality renders really quickly
  (this is the same work I've been doing for the past year but with great looking renders)
- required features
 . support low poly models that can fit in constant memory. I may simplify models to reduce their poly count
 . support a few interesting materials that produce great renders
   (tinted glass, subsurface scattering, coat)
 . basic lighting and background setup that produces great renders
 . apply all the optimizations I learned so far along with any other optimization that may improve the
   performance of the renderer (SAH BVH building, russian roulette, ...)
   UPDATE: rather than spending time on optimizations that will probably get obsolete once we move to phase 2
   focus more on the renderer features regardless of its performance (russian roulette, subsurface scattering, hard coded material kernel code, ...)

- optional features
 . transparent bg with invisible plane that allows you to change to color of the whole background while keeping
   the shadows and reflections on the floor

 HIGH QUALITY POLYGON RENDERER (PHASE II)
 ----------------------------------------
- one line summary
  enhance phase 1 renderer to support high quality models (sculptures) and optimize BVH construction/traversal
  to render the models as quickly as possible (ideally in real-time)
- required features
 . port my spheres BVH and wavefront renderer to support triangle meshes
 . explore advanced optimization techniques
 
 PBR MATERIAL EDITOR (PHASE III)
 ------------------------------
- one line summary
  allow user to configure PBR materials and replace existing sculpture materials with those
  producing incredible renders (think CGTrader Marvel/DC Comics renders) really fast
- may make sense to support Nvidia MDL at some point
 . start by implementing MDL's basic components on my own to understand the theory behind them
 . then integrate MDL with my renderer as it supports generating CUDA code directly

 OTHER DELIVERABLES IN NO PARTICULAR ORDER
 -----------------------------------------
- raylib mesh viewer that supports rendering directly to the viewport
 . we can start with render goes straight to disk
 . this will be useful when building my own rendering/material tool
- integrate with Lighthouse 2
 . we get a model loader/viewer for free
 . we get PBRT scenes loading for free
 . we get a lots of physically-based materials for free
 . we can compare performance of my renderer vs others
 . this is useful when I just want to focus on the render core and optimize it
- advanced materials: implement Disney BRDF and add UI to configure materials
  MDL seem to be a better alternative
- allow setting different material per original model color
- integrate with Optiz denoiser to greatly improve the render quality of my preview renderer

 IMPROVEMENTS IN NO PARTICULAR ORDER
 -----------------------------------
- DONE use MeshLab to simplify complex models so they can fit in constant memory
- when importing a model, define its orientation (up vector) and make sure its loading
  in the correct orientation. Makes it easier to use a standard camera position and orient
  the environment map
- camera distance is computed automatically such that the whole model is visible in the viewport
- transparent background (useful to create interesting renders in Gimp)
 . note that ideally we want to capture the full RGB of the background/floor as an ALPHA channel but no image format
   supports this
 . alternative is to treat background/floor differently when hit by primary ray
  . use a different color defined by the user that doesn't affect the scene
- resume rendering from saved file (useful when we want to add more samples to an already expensive render)
- can we preprocess the triangles to identify the ones that don't face any other triangle from the model ?
 . we could use this to quickly identify no_hits for secondary rays
- NOPE Gimp "White Balance" improves the quality of the final renderer
 . can I implement the same strategy in my renderer ?
- all rendering params are configurables from a simple test file. Create a separate file per test scene
- once I implement wavefront renderer, use CUDA graphs to optimize lunching the kernels
- Improve wavefront termination condition as follows (for offline mode):
 . track number samples completed for each pixel
 . once num samples for pixel p reach ns, increment global numDonePixels counter
 . host checks if numDonePixels == (nx * ny) every few iterations to stop the renderer
 . keep sampling pixels that completed all their samples but we don't need to account their color in the framebuffer
   if it helps keeping the logic simpler
- explore using Aila's ray-triangle intersection logic that precomputes a transformation matrix at startup
  this may reduce register usage and improve rendering performance

 POTENTIAL DIRECTION
 -------------------
* simple OpenGL model viewer
 . easily set camera position
 . easily rotate/translate the model
 . easily orient light
 . easily configure render settings: materials, light, ...
 . ideally starts CUDA renderer and displays progressive rendering
* use MDL as a guide to write my own easy to combine material blocks
  e.g. coat, dielectric and tinted glass share the same fresnel reflection/refraction logic
   find ways to make it easy to combine blocks of code to build those materials
- instead of writing generic material scattering logic, write custom code that handles the specific
  materials I want to render
- eventually I can move to a code generation/templating so I can generate kernel code on demand
* move rendering logic to the cloud and build a web editor to interact with the renderer using PixiJS
---------------------------------------------------------------------------------------------------------
PHASE I.1: POLYGON RENDERER
---------------------------------------------------------------------------------------------------------
 REQUIREMENTS
 ------------
- support triangle mesh .obj models that fit in constant memory
- support a few interesting materials that produce great renderers
 . DONE tinted glass with Beer-lambert model
 . DONE existing plastic/coat (diffuse + glass)
- DONE basic lighting and background setup that produces great renderers

 DELIVERABLES
 ------------
- great looking renders that may be too slow to renderer

 TASKS
 -----
 - DONE render obj model
- DONE floor
- DONE light and next event estimation
- DONE Lambert-Beer absorption

 NEXT (move these to their own steps later)
 ----
- apply basic optimizations from my previous work to speedup the rendering a bit
 . we should expect very good speedup with not much effort
- add subsurface-scattering material
- add OpenGL/imGUI viewer (from my spheres renderer)
 . quickly configure the scene to get high quality renderers
- Subsurface scattering material
 . https://computergraphics.stackexchange.com/questions/5214/a-recent-approach-for-subsurface-scattering

 PERF
 ----
- tinted-glass on coat 1200x800x4096 in 1045s (17m45s)
----------------------------------------------------------------------------------------------------------
PHASE I.2 BASIC OPTIMIZATIONS (got 3.5x speedup)
----------------------------------------------------------------------------------------------------------
- use the ray stats I collected and identify strategies to reduce total number of traced rays
- apply optimization strategies from my previous work without introducing a full BVH
- target 20x speedup => tinted on coat w 4096spp should render in < 1mn (vs +20mn now)
- do not worry about good design as we are mostly interested by the performance of the renderer
 
 DELIVERABLES
 ------------
- Fast renderer that can be extended with more expensive materials (in phase 1.3)  and larger models (in phase 2)
  Render tinted-glass on coat w 4096spp < 1mn
  UPDATE current performance is good enough (<7mn) for now as I will most likely move to my wavefront/BVH renderer soon

 PROGRESS
 --------
 1045s (17m45s) > 757s (12m37s) > 531s (8m51s) > 395s (6m35s) > 350s (5m50s) > 290s (4m50s) > 278s (4m38s)

 TASKS
 -----
- DONE handle floor as proper infinite plane in kernel
- DONE compute bounding box for the mesh and use it to quickly discard rays
  PERF: 1045s (17m45s) > 757s (12m37s) = 25% speedup
- DONE measue how many secondary rays are from the mesh
- DONE measure how many secondary rays are nohit
- DONE if N samples of same pixel didn't hit the model then remaining samples should just intersect the floor
  in total we pruned 2.7B rays but 2.2B of those rays were bb nohit anyway so not much performance gain
- DONE build a simplified grid acceleration structure
  for N^3 grid rays will at most traverse 3N => 
  N=2 => 4x, N=4 => 5x, N=8 => 20x
  PERF 757s > 531s (8m51s) = 30% speedup
- DONE investigate perf bottlenecks of grid (suspect its too much memory access)
 . increased register count => less occupancy
 . reduced warp efficiency
 . increase memory reads
- DONE copy grid to constant memory
  PERF 531s > 395s (6m35s)
- DONE analyse perf bottlenecks
 . increased register count => less occupancy
 . reduced warp efficiency
 . lots of execution dependency related to loading triangles from constant memory
- NOPE split kernels to reduce register usage
  do not use advanced optimizations (persistent threads, ...)
 . DONE create path struct and use it in kernel code
 . DONE introduced path.specular and fixed caustics
 UPDATE: too much complexity added too soon and register count didn't get that low (still +70 registers for the traversal logic)

- DONE interpolate vertice normals
	ptxas info    : Used 86 registers, 576 bytes cmem[0], 244 bytes cmem[2]
 . DONE rewrite intersection logic to delay computing most intersection details after we find closest hit
    ptxas info    : Used 82 registers, 576 bytes cmem[0], 264 bytes cmem[2]
 . DONE expose hit uv coordinates from hitMesh() + more replace hit_record with tri_hit
    ptxas info    : Used 78 registers, 576 bytes cmem[0], 264 bytes cmem[2]
 . DONE found small optimization with shadow rays (we don't need to intersect them with plane and we don't need to compute intersection details for them)
	PERF 395s (6m35s) > 350s (5m50s)
 . DONE copy mesh normals to global memory and expose pointer to RenderContext
 . DONE color() computes interpolated normal when hitIdx == MESH_HIT
    ptxas info    : Used 84 registers, 584 bytes cmem[0], 264 bytes cmem[2]
	PERF is worse 401s even when disabling interpolated normals
 . DONE copy normals to constant memory
	didn't improve performance

- NOPE adaptive sampling to skip pixels that don't have any specular light hit nor mix of shadow/no shadow hits
 . skip pixels that don't hit anything after X spp (X=32)
 . skip pixels that don't hit mesh in any bounce and in their primary shadow)
   PERF is actually worse, most likely because those skipped pixels weren't expensive to compute in the first place and the added
    complexity and register usage affects all pixels

- DONE russian roulette
	PERF 350s > 290s (4m50s)
 . using stats register usage goes down from 84 -> 79 !
 . perf is worse without stats!!!

- DONE investigate stat diff after material refactoring
  one issue was caused by epsilon too small causing self intersections
  some faces have a wrong orientation causing the renderer to interpret their intersection as exiting from model
 . refactor logic to always reorient normal and use other ways to identify entry/exit from model
 . fixing this issue reduced register usage to 79 and 
	PERF 290s > 278s (4m38s)
- store triangle normal in constant memory

----------------------------------------------------------------------------------------------------------
PHASE I.3 SUBSURFACE SCATTERING
----------------------------------------------------------------------------------------------------------

- DONE implement subsurface scattering
 . takes time to get used how to properly configure
 . has a lot of variation even with 16K samples
  . makes sense to implement some variation reducing techniques like splitting (less rays per pixel and more scattered rays)
  . better phase functions should improve convergence

 NOTES
 -----
- Disney BRDF initially didn't contain subsurface scattering, so we may get a lot of interesting renders without sss
- after this phase is done it makes sense to cleanup the rendering code and simplify it to fit in a single cuda file
  then write a quick tutorial explaining all the optimizations that got it to run that fast
  . similar to https://fabiensanglard.net/revisiting_the_businesscard_raytracer/card_cudc.html

----------------------------------------------------------------------------------------------------------
PHASE II SUPPORT LARGE TRIANGLE MESH MODELS
----------------------------------------------------------------------------------------------------------
 NOTES
 -----
- DONE we should start with spheres project and update it to support triangle meshes
- update bvh-renderer to be at par with grid-renderer:
 . colored background
 . support for multiple materials
 . floor/box with dedicated material
- start by making minimum changes to support triangle meshes, we don't want to refactor the code as its a big
  mess and eventually we want to move away from that project
- current spheres project no longer uses constant or texture memory
 . not sure why but I guess that's good as it will be less distraction when analysing its perf

----------------------------------------------------------------------------------------------------------
PHASE II.1 UPDATES SPHERES TO SUPPORT TRIANGLE MESHES
----------------------------------------------------------------------------------------------------------
 TASKS
 -----
- DONE start by removing colors and updating code accordingly to only use modelColor
 . bModelColor always set to true	
- update loadScene() to load triangle meshes using tinyobj
 . DONE introduce tri struct only needed during loading/bvh building
	. has a center field
 . DONE update scene to use tri* instead of sphere*
 . DONE update build_bvh() to accept tri* instead of sphere*
  . it's mostly the same, we just need to update minof() and maxof() to handle tri instead of sphere
  . we also need to update box_x/y/z_compare, if we use the tri centroids we can actually compute those centrois 
    when loading the model as tri.center that way we don't need to change box_x/y/z_compare
 . change loadFromPLY() to loadFromOBJ() and use tinyobj
- DONE after scene is loaded convert tri* to vec3* and pass them to renderContext
 . RenderContext stores tri* and numTris instead of sphere*, it also no longer contains colors
- DONE change trace_scattered() and trace_shadows() to use hit_triangle() instead of hit_point()
- DONE change update() to just use modelColor (already exists) instead of colors

- DONE found issue with teapot and bunny models: they both have holes in them
  that's why subsurface scattering looks wrong
- DONE fix loading dragon model
 . using uint16_t doesn't work for large models
- DONE make it easy to set UP vector for the camera (and floor ?)

- DONE looks like bvh traversal has a bug in it, as it tries to read non existing triangles
 . shadow rays were generated with a NaN direction

- DONE get a sense of how fast bvh renderer compared to the grid renderer
 . easiest is to change the grid renderer so that it matches the render settings of the bvh renderer
  . DONE only compare models that are yUp: teapot, bunny, dragon, catfolkrogue
	teapot scale = 100, camera.dist = 120
	bunny scale = 50, camera.dist = 120
	dragon scale = 100, camera.dist = 200
	
  . DONE camera looks at scene.bounds.max.y/2
  . DONE center model on top of floor
  . DONE camera.fov = 20
  . DONE no floor
  . DONE constant sky color
  . DONE show sky color
  . DONE same model color
  . DONE same light settings
  . DONE max bounces = 10
  . DONE disable russian roulette
  . sqrt color before converting to linear sRGB
 . some performance numbers for 512x512 1024spp
	teapot	 39s vs  120s (x3)
	bunny	131s vs  937s (x7)
	dragon  294s vs 1793s (x12)	(1024spp crashed the laptop for the grid renderer, this number is for 512spp)
- DONE fixed NaN issue in generateShadowRays() and somehow register usage went down 64 > 56 !!!

- DONE implement basic bvh building and traversal in mega-kernel renderer (previously grid renderer)
  don't worry about SAH for now
  don't worry about splitting the kernels for now
  . register count 62
	512x512 1024(settings similar to spheres) // 63 registers
	scene			uber-kernel		wavefront	speedup		speedup vs no accel
	-----			-----------		---------	-------		-------------------
	panter			4s				7s			1.75x		
	teapot			22.5s			39s			1.73x		5.3x
	bunny			15s				130s		8.66x		62.4x
	dragon			25s				294s		11.75x		71.2x
  . uber kernel is much faster than wavefront renderer !!!

- DONE there is slight difference in the rendering between spheres and cuda-raytracing
 . cuda-raytracing is consistent before/after bvh so its not related to BVH

- collect various stats for cuda-raytracing with/without BVH
 . add easy way to disable BVH traversal
 . explore various materials
 . identify useful stats and hints about when BVH is less performant
- go through my optimization notes and identify what kind of stats I should track to
  identify what to optimize next

- [optional] rewrite mega-kernel to render a single sample per pixel
  can this reduces register usage ?

 NOTES
 -----
- subsurface scattering is too slow. Eventually I will implement better phase functions so don't worry about it for now
 . it is also possible that I misconfigured the material and its causing it to scatter too much
- took me time to track the memory access issue. What I learned from it:
 . I should have a DBG mode that checks each array idx before we access and print enough hints to point to it
   when we see issues, we can enable DBG mode
 . in DBG mode track NaN in various places of the code and print a warning
- the way I convert colors in grid renderer to sRGB may be wrong
  I should probably not sqrt() the color channel before conversion

 OPTIONAL (don't do these now, leave them until we are ready to refactor the code into a new clean project)
 -------- 
- add option to show floor with a configurable size.
 . I could make it a box so it's prettier
- add versions to .bin files
- for large models, preview window lags too much
 . uncouple rendering of the window from rendering of the model
 . add "preview" mode that renders a coarse version of the model (maybe stop at some level of bvh)
- grid-based renderer could benefit from resume feature. This way we can render incrementally especially
  for complex material (like subsurface scattering)
- add scene struct to grid-based renderer
- material that draws the borders of triangles on top of the material

----------------------------------------------------------------------------------------------------------
GENERAL NOTES
----------------------------------------------------------------------------------------------------------
- useful nvprof metrics
 . achieved_occupancy
 . branch_efficiency
 . flop_count_dp: number of double precision operations (useful to confirm we aren't using any)