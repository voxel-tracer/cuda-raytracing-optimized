---------------------------------------------------------------------------------------------------------
FEATURES
---------------------------------------------------------------------------------------------------------

 LOW POLYGON RENDERER (PHASE I)
 --------------------------
- one line summary
  apply all the optimization techniques I learned so far to produce high quality renders really quickly
  (this is the same work I've been doing for the past year but with great looking renders)
- required features
 . support low poly models that can fit in constant memory. I may simplify models to reduce their poly count
 . support a few interesting materials that produce great renders
   (tinted glass, subsurface scattering, coat)
 . basic lighting and background setup that produces great renders
 . apply all the optimizations I learned so far along with any other optimization that may improve the
   performance of the renderer (SAH BVH building, russian roulette, ...)
   UPDATE: rather than spending time on optimizations that will probably get obsolete once we move to phase 2
   focus more on the renderer features regardless of its performance (russian roulette, subsurface scattering, hard coded material kernel code, ...)

- optional features
 . transparent bg with invisible plane that allows you to change to color of the whole background while keeping
   the shadows and reflections on the floor

 HIGH QUALITY POLYGON RENDERER (PHASE II)
 ----------------------------------------
- one line summary
  enhance phase 1 renderer to support high quality models (sculptures) and optimize BVH construction/traversal
  to render the models as quickly as possible (ideally in real-time)
- required features
 . port my spheres BVH and wavefront renderer to support triangle meshes
 . explore advanced optimization techniques
 
 PBR MATERIAL EDITOR (PHASE III)
 ------------------------------
- one line summary
  allow user to configure PBR materials and replace existing sculpture materials with those
  producing incredible renders (think CGTrader Marvel/DC Comics renders) really fast
- may make sense to support Nvidia MDL at some point
 . start by implementing MDL's basic components on my own to understand the theory behind them
 . then integrate MDL with my renderer as it supports generating CUDA code directly

 OTHER DELIVERABLES IN NO PARTICULAR ORDER
 -----------------------------------------
- raylib mesh viewer that supports rendering directly to the viewport
 . we can start with render goes straight to disk
 . this will be useful when building my own rendering/material tool
- integrate with Lighthouse 2
 . we get a model loader/viewer for free
 . we get PBRT scenes loading for free
 . we get a lots of physically-based materials for free
 . we can compare performance of my renderer vs others
 . this is useful when I just want to focus on the render core and optimize it
- advanced materials: implement Disney BRDF and add UI to configure materials
  MDL seem to be a better alternative
- allow setting different material per original model color
- integrate with Optiz denoiser to greatly improve the render quality of my preview renderer

 IMPROVEMENTS IN NO PARTICULAR ORDER
 -----------------------------------
- use MeshLab to simplify complex models so they can fit in constant memory
- when importing a model, define its orientation (up vector) and make sure its loading
  in the correct orientation. Makes it easier to use a standard camera position and orient
  the environment map
- camera distance is computed automatically such that the whole model is visible in the viewport
- transparent background (useful to create interesting renders in Gimp)
 . note that ideally we want to capture the full RGB of the background/floor as an ALPHA channel but no image format
   supports this
 . alternative is to treat background/floor differently when hit by primary ray
  . use a different color defined by the user that doesn't affect the scene
- resume rendering from saved file (useful when we want to add more samples to an already expensive render)
- can we preprocess the triangles to identify the ones that don't face any other triangle from the model ?
 . we could use this to quickly identify no_hits for secondary rays
- Gimp "White Balance" improves the quality of the final renderer
 . can I implement the same strategy in my renderer ?
- all rendering params are configurables from a simple test file. Create a separate file per test scene
- once I implement wavefront renderer, use CUDA graphs to optimize lunching the kernels
- Improve wavefront termination condition as follows (for offline mode):
 . track number samples completed for each pixel
 . once num samples for pixel p reach ns, increment global numDonePixels counter
 . host checks if numDonePixels == (nx * ny) every few iterations to stop the renderer
 . keep sampling pixels that completed all their samples but we don't need to account their color in the framebuffer
   if it helps keeping the logic simpler
- explore using Aila's ray-triangle intersection logic that precomputes a transformation matrix at startup
  this may reduce register usage and improve rendering performance

 POTENTIAL DIRECTION
 -------------------
* use MDL as a guide to write my own easy to combine material blocks
  e.g. coat, dielectric and tinted glass share the same fresnel reflection/refraction logic
   find ways to make it easy to combine blocks of code to build those materials
- instead of writing generic material scattering logic, write custom code that handles the specific
  materials I want to render
- eventually I can move to a code generation/templating so I can generate kernel code on demand
* move rendering logic to the cloud and build a web editor to interact with the renderer using PixiJS
---------------------------------------------------------------------------------------------------------
PHASE I.1: POLYGON RENDERER
---------------------------------------------------------------------------------------------------------
 REQUIREMENTS
 ------------
- support triangle mesh .obj models that fit in constant memory
- support a few interesting materials that produce great renderers
 . DONE tinted glass with Beer-lambert model
 . DONE existing plastic/coat (diffuse + glass)
- DONE basic lighting and background setup that produces great renderers

 DELIVERABLES
 ------------
- great looking renders that may be too slow to renderer

 TASKS
 -----
 - DONE render obj model
- DONE floor
- DONE light and next event estimation
- DONE Lambert-Beer absorption

 NEXT (move these to their own steps later)
 ----
- apply basic optimizations from my previous work to speedup the rendering a bit
 . we should expect very good speedup with not much effort
- add subsurface-scattering material
- add OpenGL/imGUI viewer (from my spheres renderer)
 . quickly configure the scene to get high quality renderers
- Subsurface scattering material
 . https://computergraphics.stackexchange.com/questions/5214/a-recent-approach-for-subsurface-scattering

 PERF
 ----
- tinted-glass on coat 1200x800x4096 in 1045s (17m45s)
----------------------------------------------------------------------------------------------------------
PHASE I.2 BASIC OPTIMIZATIONS
----------------------------------------------------------------------------------------------------------
- use the ray stats I collected and identify strategies to reduce total number of traced rays
- apply optimization strategies from my previous work without introducing a full BVH
- target 20x speedup => tinted on coat w 4096spp should render in < 1mn (vs +20mn now)
- do not worry about good design as we are mostly interested by the performance of the renderer
 
 DELIVERABLES
 ------------
- Fast renderer that can be extended with more expensive materials (in phase 1.3)  and larger models (in phase 2)
  Render tinted-glass on coat w 4096spp < 1mn
  UPDATE current performance is good enough (<7mn) for now as I will most likely move to my wavefront/BVH renderer soon

 PROGRESS
 --------
 1045s (17m45s) > 757s (12m37s) > 531s (8m51s) > 395s (6m35s) > 350s (5m50s) > 290s (4m50s) > 278s (4m38s)

 TASKS
 -----
- DONE handle floor as proper infinite plane in kernel
- DONE compute bounding box for the mesh and use it to quickly discard rays
  PERF: 1045s (17m45s) > 757s (12m37s) = 25% speedup
- DONE measue how many secondary rays are from the mesh
- DONE measure how many secondary rays are nohit
- DONE if N samples of same pixel didn't hit the model then remaining samples should just intersect the floor
  in total we pruned 2.7B rays but 2.2B of those rays were bb nohit anyway so not much performance gain
- DONE build a simplified grid acceleration structure
  for N^3 grid rays will at most traverse 3N => 
  N=2 => 4x, N=4 => 5x, N=8 => 20x
  PERF 757s > 531s (8m51s) = 30% speedup
- DONE investigate perf bottlenecks of grid (suspect its too much memory access)
 . increased register count => less occupancy
 . reduced warp efficiency
 . increase memory reads
- DONE copy grid to constant memory
  PERF 531s > 395s (6m35s)
- DONE analyse perf bottlenecks
 . increased register count => less occupancy
 . reduced warp efficiency
 . lots of execution dependency related to loading triangles from constant memory
- NOPE split kernels to reduce register usage
  do not use advanced optimizations (persistent threads, ...)
 . DONE create path struct and use it in kernel code
 . DONE introduced path.specular and fixed caustics
 UPDATE: too much complexity added too soon and register count didn't get that low (still +70 registers for the traversal logic)

- DONE interpolate vertice normals
	ptxas info    : Used 86 registers, 576 bytes cmem[0], 244 bytes cmem[2]
 . DONE rewrite intersection logic to delay computing most intersection details after we find closest hit
    ptxas info    : Used 82 registers, 576 bytes cmem[0], 264 bytes cmem[2]
 . DONE expose hit uv coordinates from hitMesh() + more replace hit_record with tri_hit
    ptxas info    : Used 78 registers, 576 bytes cmem[0], 264 bytes cmem[2]
 . DONE found small optimization with shadow rays (we don't need to intersect them with plane and we don't need to compute intersection details for them)
	PERF 395s (6m35s) > 350s (5m50s)
 . DONE copy mesh normals to global memory and expose pointer to RenderContext
 . DONE color() computes interpolated normal when hitIdx == MESH_HIT
    ptxas info    : Used 84 registers, 584 bytes cmem[0], 264 bytes cmem[2]
	PERF is worse 401s even when disabling interpolated normals
 . DONE copy normals to constant memory
	didn't improve performance

- NOPE adaptive sampling to skip pixels that don't have any specular light hit nor mix of shadow/no shadow hits
 . skip pixels that don't hit anything after X spp (X=32)
 . skip pixels that don't hit mesh in any bounce and in their primary shadow)
   PERF is actually worse, most likely because those skipped pixels weren't expensive to compute in the first place and the added
    complexity and register usage affects all pixels

- DONE russian roulette
	PERF 350s > 290s (4m50s)
 . using stats register usage goes down from 84 -> 79 !
 . perf is worse without stats!!!

- DONE investigate stat diff after material refactoring
  one issue was caused by epsilon too small causing self intersections
  some faces have a wrong orientation causing the renderer to interpret their intersection as exiting from model
 . refactor logic to always reorient normal and use other ways to identify entry/exit from model
 . fixing this issue reduced register usage to 79 and 
	PERF 290s > 278s (4m38s)
- store triangle normal in constant memory

----------------------------------------------------------------------------------------------------------
PHASE I.3 SUBSURFACE SCATTERING
----------------------------------------------------------------------------------------------------------

- DONE implement subsurface scattering
 . takes time to get used how to properly configure
 . has a lot of variation even with 16K samples
  . makes sense to implement some variation reducing techniques like splitting (less rays per pixel and more scattered rays)
  . better phase functions should improve convergence

 NOTES
 -----
- Disney BRDF initially didn't contain subsurface scattering, so we may get a lot of interesting renders without sss
- after this phase is done it makes sense to cleanup the rendering code and simplify it to fit in a single cuda file
  then write a quick tutorial explaining all the optimizations that got it to run that fast
  . similar to https://fabiensanglard.net/revisiting_the_businesscard_raytracer/card_cudc.html

----------------------------------------------------------------------------------------------------------
PHASE II SUPPORT LARGE TRIANGLE MESH MODELS
----------------------------------------------------------------------------------------------------------
 NOTES
 -----
- we should start with spheres project and update it to support triangle meshes
- note that it also only supports diffuse brdf for now so we'll need to update that as well (eventually)
- start by making minimum changes to support triangle meshes, we don't want to refactor the code as its a big
  mess and eventually we want to move away from that project
- current spheres project no longer uses constant or texture memory
 . not sure why but I guess that's good as it will be less distraction when analysing its perf

----------------------------------------------------------------------------------------------------------
PHASE II.1 UPDATES SPHERES TO SUPPORT TRIANGLE MESHES
----------------------------------------------------------------------------------------------------------
 TASKS
 -----
- DONE start by removing colors and updating code accordingly to only use modelColor
 . bModelColor always set to true	
- update loadScene() to load triangle meshes using tinyobj
 . DONE introduce tri struct only needed during loading/bvh building
	. has a center field
 . DONE update scene to use tri* instead of sphere*
 . DONE update build_bvh() to accept tri* instead of sphere*
  . it's mostly the same, we just need to update minof() and maxof() to handle tri instead of sphere
  . we also need to update box_x/y/z_compare, if we use the tri centroids we can actually compute those centrois 
    when loading the model as tri.center that way we don't need to change box_x/y/z_compare
 . change loadFromPLY() to loadFromOBJ() and use tinyobj
- DONE after scene is loaded convert tri* to vec3* and pass them to renderContext
 . RenderContext stores tri* and numTris instead of sphere*, it also no longer contains colors
- DONE change trace_scattered() and trace_shadows() to use hit_triangle() instead of hit_point()
- DONE change update() to just use modelColor (already exists) instead of colors


- once I get the project to build and render, go through the code and make a list of fixes to make
 . avoid refactoring, just add those to the optional list
 . focus on rendering fixes that I learned from my new projects

 NOTES
 -----
- I can load teapot and bunny but I'm having trouble with stanford dragon model

 OPTIONAL (don't do these now, leave them until we are ready to refactor the code into a new clean project)
 -------- 
- make it easy to set UP vector for the camera (and floor ?)
- add option to show floor with a configurable size.
 . I could make it a box so it's prettier
- add versions to .bin files
----------------------------------------------------------------------------------------------------------
GENERAL NOTES
----------------------------------------------------------------------------------------------------------
- useful nvprof metrics
 . achieved_occupancy
 . branch_efficiency
 . flop_count_dp: number of double precision operations (useful to confirm we aren't using any)